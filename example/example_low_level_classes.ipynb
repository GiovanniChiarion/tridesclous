{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is necessary for having figures directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "from tridesclous import DataIO\n",
    "import tridesclous as tdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Locust dataset from zenedo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "name = 'locust20010201.hdf5'\n",
    "distantfile = 'https://zenodo.org/record/21589/files/'+name\n",
    "localfile = name\n",
    "if not os.path.exists(localfile):\n",
    "    urlretrieve(distantfile, localfile)\n",
    "hdf = h5py.File(localfile,'r')\n",
    "\n",
    "#create array from the first trials\n",
    "ch_names = ['ch09','ch11','ch13','ch16']\n",
    "array_sigs = np.array([hdf['Continuous_1']['trial_01'][name][...] for name in ch_names]).transpose()\n",
    "array_sigs = (array_sigs.astype('float32') - 2**15.) / 2**15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataIO\n",
    "\n",
    "Create our data manager and append some data into it.\n",
    "Note that our data is already filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataio = DataIO(dirname = 'Dataset one segment')\n",
    "dataio.append_signals(array_sigs, seg_num = 0,t_start = 0., sampling_rate =  15000.,\n",
    "                    already_hp_filtered = True, channels = ch_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataio #equivalent to data.summary(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dataio.summary(level=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signals = pandas.DataFrame\n",
    "Each segment of data is a pandas.DataFrame and its index is the time coded in second.\n",
    "\n",
    "So we can acces with times or sample position with DataFrame.loc and dataFrame.iloc.\n",
    "See http://pandas.pydata.org/pandas-docs/stable/indexing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signals = dataio.get_signals(seg_num=0, filtered =True)\n",
    "\n",
    "chunk = signals.iloc[45225:45450]  #slicing by sample\n",
    "chunk = signals.loc[3.015:3.030]  #slicing by time\n",
    "\n",
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signals is pure pandas.DataFrame so We can user all pandas facilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signals.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting is also easy so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunk.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tridesclous have some function that directly work on this kind of (signals) DataFrame:\n",
    "  * normalize_signals\n",
    "  * derivative_signals\n",
    "  * rectify_signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normed_sigs = tdc.normalize_signals(signals)\n",
    "deriv_sigs = tdc.derivative_signals(signals)\n",
    "retified_sigs = tdc.rectify_signals(normed_sigs, threshold = -4)\n",
    "\n",
    "fig, axs = pyplot.subplots(ncols = 3, figsize = (15, 8))\n",
    "normed_sigs[3.14:3.22].plot(ax = axs[0])\n",
    "deriv_sigs[3.14:3.22].plot(ax = axs[1])\n",
    "retified_sigs[3.14:3.22].plot(ax = axs[2])\n",
    "axs[2].set_ylim(axs[0].get_ylim())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak detection\n",
    "The class  PeakDetector offers facilities:\n",
    "  * to detect peaks.\n",
    "\n",
    "This return peak_pos in index.\n",
    "\n",
    "Having pek with times is easy : \n",
    "peak_time = signals.index[peaks_pos]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peakdetector = tdc.PeakDetector(signals)\n",
    "peaks_pos_bad = peakdetector.detect_peaks(threshold=-4, peak_sign = '-', n_span = 2)\n",
    "peaks_index_bad = signals.index[peaks_pos_bad]\n",
    "\n",
    "peaks_pos_ok = peakdetector.detect_peaks(threshold=-5, peak_sign = '-', n_span = 5)\n",
    "peaks_index_ok = signals.index[peaks_pos_ok]\n",
    "\n",
    "fig, axs = pyplot.subplots(nrows = 2, ncols = 2, figsize = (15, 8))\n",
    "\n",
    "\n",
    "t1, t2 = 3.163, 3.166\n",
    "chunk = normed_sigs[t1:t2]\n",
    "chunk_rectified = peakdetector.rectified_sigs.sum(axis=1)[t1:t2]\n",
    "\n",
    "#bad\n",
    "chunk.plot(ax = axs[0,0])\n",
    "chunk_rectified.plot(ax = axs[1,0])\n",
    "peaks_value_bad = normed_sigs.loc[peaks_index_bad]\n",
    "peaks_value_bad[t1:t2].plot(marker = 'o', linestyle = 'None', ax = axs[0,0], color = 'k')\n",
    "axs[0,0].set_title('n_span=2')\n",
    "peaks_value_bad = chunk_rectified.loc[peaks_index_bad]\n",
    "peaks_value_bad[t1:t2].plot(marker = 'o', linestyle = 'None', ax = axs[1,0], color = 'k')\n",
    "\n",
    "\n",
    "\n",
    "#OK\n",
    "chunk.plot(ax = axs[0,1])\n",
    "chunk_rectified.plot(ax = axs[1,1])\n",
    "peaks_value_ok = normed_sigs.loc[peaks_index_ok]\n",
    "peaks_value_ok[t1:t2].plot(marker = 'o', linestyle = 'None', ax = axs[0,1], color = 'k')\n",
    "axs[0,1].set_title('n_span=5')\n",
    "peaks_value_ok = chunk_rectified.loc[peaks_index_ok]\n",
    "peaks_value_ok[t1:t2].plot(marker = 'o', linestyle = 'None', ax = axs[1,1], color = 'k')\n",
    "\n",
    "\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_ylim(-20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extract waveform\n",
    "\n",
    "The class WaveformExtractor offers facilities to:\n",
    "    * extreact waveforms\n",
    "    * extract noise (=fake waveform in between peaks)\n",
    "    * keep or exclude good events\n",
    "    * find good limits for the cut.\n",
    "   \n",
    "The wavefroms object os also a pandas.DataFrame with:\n",
    "   * index is peak_pos\n",
    "   * columns is MultiIndex (channels, samples) where samples is from n_left to n_rigth [-10, -9, ..., 0, 1, ...,  30]. 0 is peak.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#start with larger sweep\n",
    "waveformextractor = tdc.WaveformExtractor(peakdetector, n_left=-30, n_right=50)\n",
    "med, mad = tdc.median_mad(waveformextractor.long_waveforms)\n",
    "fig, axs = pyplot.subplots(nrows =2)\n",
    "med.plot(ax = axs[0], ylim = (-6, 2))\n",
    "mad.plot(ax = axs[1], ylim = (0, 5))\n",
    "\n",
    "# make some noise to compare\n",
    "noise = waveformextractor.extract_noise(-30, 50, size=1000, safety_factor=2)\n",
    "med_noise, mad_noise = tdc.median_mad(noise)\n",
    "med_noise.plot(ax = axs[0], ylim = (-6, 2), color = 'r')\n",
    "mad_noise.plot(ax = axs[1], ylim = (0, 5), color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the good limits\n",
    "limit_left, limit_right = waveformextractor.find_good_limits(mad_threshold = 1.1)\n",
    "print(limit_left, limit_right)\n",
    "waveformextractor.plot_good_limit()\n",
    "short_wf = waveformextractor.get_ajusted_waveforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection and Clustering\n",
    "\n",
    "The class Clustering offers facilities to:\n",
    "  * project waveform with : PCA, ...\n",
    "  * clusters them with kmeans, EM+GMM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# work on shorted waveforms (see good limits)\n",
    "clustering = tdc.Clustering(short_wf)\n",
    "\n",
    "# do a PCA\n",
    "features = clustering.project(method = 'pca', n_components = 5)\n",
    "features\n",
    "\n",
    "clustering.plot_projection(plot_density = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try to clusters\n",
    "labels = clustering.find_clusters(7)\n",
    "df = pd.concat([features, labels], axis=1)\n",
    "\n",
    "clustering.plot_projection(plot_density = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalogue = clustering.construct_catalogue()\n",
    "clustering.plot_catalogue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interactive windows\n",
    "\n",
    "This work only on a localhost when PyQt4+pyqtgraph is installed.\n",
    "\n",
    "Do not forget the %gui qt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%gui qt4\n",
    "import pyqtgraph as pg\n",
    "app = pg.mkQApp()\n",
    "win = tdc.SpikeSortingWindow.from_classes(dataio, peakdetector, waveformextractor, clustering)\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Peeler\n",
    "The class peeler help:\n",
    "   * estimate jitter\n",
    "   * predict spiketrain\n",
    "   * subtract and get reisuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signals = peakdetector.normed_sigs\n",
    "peeler = tdc.Peeler(signals, catalogue,  limit_left, limit_right,\n",
    "                        threshold=-4, peak_sign = '-', n_span = 5)\n",
    "\n",
    "#Peel at level=0\n",
    "prediction0, residuals0 = peeler.peel()\n",
    "fig, axs = pyplot.subplots(nrows = 2)\n",
    "axs[0].plot(prediction0)\n",
    "axs[1].plot(residuals0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Peel at level=1\n",
    "prediction1, residuals1 = peeler.peel()\n",
    "fig, axs = pyplot.subplots(nrows = 2)\n",
    "axs[0].plot(prediction1)\n",
    "axs[1].plot(residuals1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *tridesclous* example with locust dataset\n",
    "\n",
    "Here a detail notebook that detail the locust dataset recodring by Christophe Pouzat.\n",
    "\n",
    "This dataset is our classic.\n",
    "It has be analyse yet by several tools in R, Python or C:\n",
    "  * https://github.com/christophe-pouzat/PouzatDetorakisEuroScipy2014\n",
    "  * https://github.com/christophe-pouzat/SortingABigDataSetWithPython\n",
    "  * http://xtof.perso.math.cnrs.fr/locust.html\n",
    "\n",
    "So we can compare the result.\n",
    "\n",
    "The original datasets is here https://zenodo.org/record/21589\n",
    "\n",
    "But we will work on a very small subset on github https://github.com/tridesclous/tridesclous_datasets/tree/master/locust\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In *tridesclous*, the spike sorting is done in several step:\n",
    "  * Define the datasource and working path. (class DataIO)\n",
    "  * Construct a *catalogue* (class CatalogueConstructor) on a short chunk of data (for instance 60s)\n",
    "    with several sub step :\n",
    "    * signal pre-processing:\n",
    "      * high pass filter (optional)\n",
    "      * removal of common reference (optional)\n",
    "      * noise estimation (median/mad) on a small chunk\n",
    "      * normalisation = robust z-score\n",
    "    * peak detection\n",
    "    * extract some waveform. Unecessary and impossible to extract them all.\n",
    "    * find rational limit of waveforms (n_left/n_right)\n",
    "    * project theses waveforms in smaller dimention (pca, ...)\n",
    "    * find cluster\n",
    "    * clean with GUI (class CatalogueWindow)\n",
    "    * save centroids (median+mad + first and second derivative)\n",
    "  * Apply the *Peeler* (class Peeler) on the long term signals. With several sub steps:\n",
    "     * same signal preprocessing than before\n",
    "     * find peaks\n",
    "     * find the best cluster in catalogue for each peak\n",
    "     * find the intersample jitter\n",
    "     * remove the oversampled waveforms from the signals until there are not peaks in the signals.\n",
    "     * check with GUI (class PeelerWindow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tridesclous as tdc\n",
    "\n",
    "from tridesclous import DataIO, CatalogueConstructor, Peeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download a small dataset\n",
    "\n",
    "trideclous provide some datasets than can be downloaded with **download_dataset**.\n",
    "\n",
    "Note this dataset contains 2 trials in 2 different files. (the original contains more!)\n",
    "\n",
    "Each file is considers as a *segment*. *tridesclous* automatically deal with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/samuel/Documents/projet/tridesclous/example/locust/locust_trial_01.raw', '/home/samuel/Documents/projet/tridesclous/example/locust/locust_trial_02.raw']\n",
      "{'total_channel': 4, 'sample_rate': 15000.0, 'dtype': 'int16'}\n"
     ]
    }
   ],
   "source": [
    "#download dataset\n",
    "localdir, filenames, params = tdc.download_dataset(name='locust')\n",
    "print(filenames)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataIO = define datasource and working dir\n",
    "\n",
    "\n",
    "Theses 2 files are in **RawData** format this means binary format with interleaved channels.\n",
    "\n",
    "Our dataset contains 2 segment of 28.8 second each, 4 channels. The sample rate is 15kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataIO <id: 140599959595664> \n",
      "  workdir: tridesclous_locust\n",
      "  sample_rate: 15000.0\n",
      "  total_channel: 4\n",
      "  channel_groups: 0 [0 1 2 3]\n",
      "  nb_segment: 2\n",
      "  length: 431548 431548\n",
      "  durations: 28.8 28.8 s.\n"
     ]
    }
   ],
   "source": [
    "#create a DataIO\n",
    "import os, shutil\n",
    "dirname = 'tridesclous_locust'\n",
    "if os.path.exists(dirname):\n",
    "    #remove is already exists\n",
    "    shutil.rmtree(dirname)    \n",
    "dataio = DataIO(dirname=dirname)\n",
    "\n",
    "# feed DataIO\n",
    "dataio.set_data_source(type='RawData', filenames=filenames, **params)\n",
    "\n",
    "print(dataio)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatalogueConstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatalogueConstructor <id: 140599959472168> \n",
      "  workdir: tridesclous_locust/channel_group_0/catalogue_constructor\n",
      "  Signal pre-processing not done yet\n"
     ]
    }
   ],
   "source": [
    "catalogueconstructor = CatalogueConstructor(dataio=dataio)\n",
    "print(catalogueconstructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some parameters for the pre-processing step.\n",
    "\n",
    "For a complet description of each params see main documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogueconstructor.set_preprocessor_params(chunksize=1024,\n",
    "            common_ref_removal=False,\n",
    "            highpass_freq=300.,\n",
    "            backward_chunksize=1280,\n",
    "            peak_sign='-',\n",
    "            relative_threshold=7,\n",
    "            peak_span=0.0005,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the noise on a small chunk of filtered signals.\n",
    "This compute medians and mad of each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.33329058  0.97232521  1.79204416  0.52885079]\n",
      "[ 57.52484894  52.35477066  63.70387268  51.0644455 ]\n"
     ]
    }
   ],
   "source": [
    "catalogueconstructor.estimate_signals_noise(seg_num=0, duration=15.)\n",
    "print(catalogueconstructor.signals_medians)\n",
    "print(catalogueconstructor.signals_mads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the main loop: signal preprocessing + peak detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_signalprocessor 0.7115417329987395 s\n",
      "CatalogueConstructor <id: 140599959472168> \n",
      "  workdir: tridesclous_locust/channel_group_0/catalogue_constructor\n",
      "  nb_peak: 1126\n",
      "  nb_peak_by_segment: 552, 574\n",
      "  cluster_labels [-10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "catalogueconstructor.run_signalprocessor(duration=60.)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print('run_signalprocessor', t2-t1, 's')\n",
    "print(catalogueconstructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract some waveforms\n",
    "\n",
    "Take some waveforms in the signals *n_left/n_right* must be choosen arbitrary but lon enought.\n",
    "Better limits will be set later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatalogueConstructor <id: 140599959472168> \n",
      "  workdir: tridesclous_locust/channel_group_0/catalogue_constructor\n",
      "  nb_peak: 1126\n",
      "  nb_peak_by_segment: 552, 574\n",
      "  n_left -25 n_right 40\n",
      "  some_waveforms.shape: (1126, 65, 4)\n",
      "  cluster_labels [-10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catalogueconstructor.extract_some_waveforms(n_left=-25, n_right=40, mode='rand', nb_max=10000, align_waveform=True)\n",
    "print(catalogueconstructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find good limits for waveforms and re-extract\n",
    "\n",
    "To avoid useless portion of signal on the sides of peaks we take smaller sweep.\n",
    "This technics is based on the MAD. We take only central zone where the MAD is above the noise.\n",
    "Noise is 1. In practice we take a bit more 1.1\n",
    "\n",
    "Here the methods give a \"good limts\" of n_left -10 n_right 15.\n",
    "\n",
    "So the shape of waveforms become smaller.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatalogueConstructor <id: 140599959472168> \n",
      "  workdir: tridesclous_locust/channel_group_0/catalogue_constructor\n",
      "  nb_peak: 1126\n",
      "  nb_peak_by_segment: 552, 574\n",
      "  n_left -10 n_right 13\n",
      "  some_waveforms.shape: (1126, 23, 4)\n",
      "  cluster_labels [-10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_left, n_right = catalogueconstructor.find_good_limits(mad_threshold = 1.1,)\n",
    "print(catalogueconstructor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project to smaller space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project 0.05169410499911464\n",
      "CatalogueConstructor <id: 140599959472168> \n",
      "  workdir: tridesclous_locust/channel_group_0/catalogue_constructor\n",
      "  nb_peak: 1126\n",
      "  nb_peak_by_segment: 552, 574\n",
      "  n_left -10 n_right 13\n",
      "  some_waveforms.shape: (1126, 23, 4)\n",
      "  some_features.shape: (1126, 5)\n",
      "  cluster_labels [-10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "catalogueconstructor.project(method='pca', n_components=5)\n",
    "t2 = time.perf_counter()\n",
    "print('project', t2-t1)\n",
    "print(catalogueconstructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find_clusters 0.16290489899984095\n",
      "CatalogueConstructor <id: 140599959472168> \n",
      "  workdir: tridesclous_locust/channel_group_0/catalogue_constructor\n",
      "  nb_peak: 1126\n",
      "  nb_peak_by_segment: 552, 574\n",
      "  n_left -10 n_right 13\n",
      "  some_waveforms.shape: (1126, 23, 4)\n",
      "  some_features.shape: (1126, 5)\n",
      "  cluster_labels [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "catalogueconstructor.find_clusters(method='kmeans', n_clusters=12)\n",
    "t2 = time.perf_counter()\n",
    "print('find_clusters', t2-t1)\n",
    "print(catalogueconstructor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open CatalogueWindow for visual check\n",
    "\n",
    "At the end we can save the catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct_catalogue 0.11879534400031844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%gui qt5\n",
    "import pyqtgraph as pg\n",
    "app = pg.mkQApp()\n",
    "win = tdc.CatalogueWindow(catalogueconstructor)\n",
    "win.show()\n",
    "app.exec_()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a snappshot of CatalogueWindow\n",
    "\n",
    "<img src=\"../doc/img/snapshot_cataloguewindow.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct_catalogue 0.13998361099947942\n"
     ]
    }
   ],
   "source": [
    "catalogueconstructor.save_catalogue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peeler\n",
    "\n",
    "Create and run the Peeler.\n",
    "It should be pretty fast, here the computation take 1.32s for 28.8x2s of signal. This is a speed up of 43 over real time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peeler.run 1.3970982890004962\n",
      "\n",
      "seg_num 0 nb_spikes 568\n",
      "seg_num 1 nb_spikes 582\n"
     ]
    }
   ],
   "source": [
    "initial_catalogue = dataio.load_catalogue(chan_grp=0)\n",
    "\n",
    "peeler = Peeler(dataio)\n",
    "peeler.change_params(catalogue=initial_catalogue, n_peel_level=2)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "peeler.run()\n",
    "t2 = time.perf_counter()\n",
    "print('peeler.run', t2-t1)\n",
    "\n",
    "print()\n",
    "for seg_num in range(dataio.nb_segment):\n",
    "    spikes = dataio.get_spikes(seg_num)\n",
    "    print('seg_num', seg_num, 'nb_spikes', spikes.size)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open PeelerWindow for visual checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%gui qt5\n",
    "import pyqtgraph as pg\n",
    "app = pg.mkQApp()\n",
    "win = tdc.PeelerWindow(dataio=dataio, catalogue=initial_catalogue)\n",
    "win.show()\n",
    "app.exec_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a snappshot of PeelerWindow\n",
    "\n",
    "<img src=\"../doc/img/snapshot_peelerwindow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
